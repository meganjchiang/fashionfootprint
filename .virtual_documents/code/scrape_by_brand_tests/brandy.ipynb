# import statements
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from lxml import html
from bs4 import BeautifulSoup
import requests
import time
import re


# reading CSVs to do the thing
df = pd.read_csv("../../data/youtube_data/brandy_melville_youtube_data.csv")
df.head(2)


# initial function
def scrape_brandy(url):
    try:
        # Set Chrome options for headless mode
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        
        # Initialize the WebDriver
        with webdriver.Chrome(options=chrome_options) as driver:
            driver.get(url)
            
            # Get the page source after interactions
            page_source = driver.page_source
            driver.quit()
        
        # Parse the page source with Beautiful Soup
        soup = BeautifulSoup(page_source, "html.parser")
        
        # Find the <div> tag with class "product__description rte"
        data_element = soup.find("div", class_="product__description rte")
        title_element = soup.find("h1", class_="product__title")
        title = title_element.text.strip()
        
        if data_element:
            data_text = data_element.text.strip().replace('\xa0', ' ')
            # Add space between each section of the output
            data_text = data_text.replace('Fabrics:', ' Fabrics:')
            data_text = data_text.replace('Measurement:', ' Measurement:')
            data_text = data_text.replace('Made in:', ' Made in:')
            return title, data_text
        else:
            return "Data element not found on the page."
            
    except Exception as e:
        return f"An error occurred: {str(e)}"

# URL of the webpage you want to scrape
url = "https://us.brandymelville.com/products/chloe-radio-silence-top-3"
# Call the function to scrape the website
data = scrape_brandy(url)
print(data)


# test code!! It works!!
top_row = df.iloc[1]
links_list = top_row["Links"].split('\n')

for link in links_list:
    scraped_data = scrape_brandy(link)
    if scraped_data:
        print(scraped_data)
        print()
    time.sleep(3)


# works!!! for items with singular component
import re
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup

def scrape_brandy(url):
    try:
        # Set Chrome options for headless mode
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        
        # Initialize the WebDriver
        with webdriver.Chrome(options=chrome_options) as driver:
            driver.get(url)
            
            # Get the page source after interactions
            page_source = driver.page_source
        
        # Parse the page source with Beautiful Soup
        soup = BeautifulSoup(page_source, "html.parser")
        
        # Find the <div> tag with class "product__description rte"
        data_element = soup.find("div", class_="product__description rte")
        title_element = soup.find("h1", class_="product__title")
        title = title_element.text.strip()
        
        if data_element:
            # Extract text content and remove HTML tags
            data_text = data_element.get_text(separator=' ', strip=True)
            print(data_text)
            
            # Extract material makeup
            materials = {}
            fabric_match = re.search(r'Fabrics:\s*((?:\d+\s*%?\s*\w+\s*,?\s*)+)\s*', data_text, re.IGNORECASE)
            if fabric_match:
                fabric_string = fabric_match.group(1)
                fabric_percentages = re.findall(r'(\d+)\s*%?\s*(\w+)', fabric_string)
                for percent, fabric in fabric_percentages:
                    materials[fabric.lower()] = int(percent)
            
            # Construct the final dictionary
            final_data = {'item': title}
            final_data.update(materials)
            
            return final_data
        else:
            return "Data element not found on the page."
            
    except Exception as e:
        return f"An error occurred: {str(e)}"

# URL of the webpage you want to scrape
url="https://us.brandymelville.com/products/nadia-skirt?pr_prod_strat=jac&pr_rec_id=4c9989488&pr_rec_pid=7282719391953&pr_ref_pid=5605883871396&pr_seq=uniform"
# Call the function to scrape the website
data = scrape_brandy(url)
print(data)






## WORKS FOR ITEMS WITH MULTIPLE COMPONENTS!!! 
def scrape_brandy_done(url):
    try:
        # Set Chrome options for headless mode
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        
        # Initialize the WebDriver
        with webdriver.Chrome(options=chrome_options) as driver:
            driver.get(url)
            
            # Get the page source after interactions
            page_source = driver.page_source
        
        # Parse the page source with Beautiful Soup
        soup = BeautifulSoup(page_source, "html.parser")
        
        # Find the <div> tag with class "product__description rte"
        data_element = soup.find("div", class_="product__description rte")
        title_element = soup.find("h1", class_="product__title")
        title = title_element.text.strip()
        
        if data_element:
            # Extract text content and remove HTML tags
            data_text = data_element.get_text(separator=' ', strip=True)
            print(data_text)
            
            # Extract material makeup
            materials = {}
            fabric_matches = re.findall(r'(\w+):\s*(.*?)\s*(?=(?:\w+:)|$)', data_text, re.DOTALL)
            for item, fabric_string in fabric_matches:
                if item.lower() == 'fabrics':
                    fabric_percentages = re.findall(r'(\d+)\s*%?\s*(\w+)', fabric_string)
                    for percent, fabric in fabric_percentages:
                        fabric_key = fabric.lower()
                        materials[fabric_key] = int(percent)
                else:
                    continue
            
            # Construct the final dictionary
            final_data = {'item': title}
            final_data.update(materials)
            
            return final_data
        else:
            return "Data element not found on the page."
            
    except Exception as e:
        return f"An error occurred: {str(e)}"

# URL of the webpage you want to scrape
url="https://us.brandymelville.com/products/keira-eyelet-sweatshorts-1?pr_prod_strat=jac&pr_rec_id=eb90ce185&pr_rec_pid=7322624000209&pr_ref_pid=5763454632100&pr_seq=uniform"
# Call the function to scrape the website
data = scrape_brandy_done(url)
print(data)



# You dont have to do this this is for getting the links from the CSV
def scrape_and_update(row):
    links_list = row["Links"].split('\n')
    scraped_data_combined = ""

    for link in links_list:
        print(f"Scraping data from link: {link}")
        scraped_data = scrape_brandy_done(link)
        if scraped_data:
            scraped_data_combined += str(scraped_data) + "\n"
        time.sleep(3)

    return scraped_data_combined


df["ScrapedData"] = df.apply(scrape_and_update, axis=1)


df.to_csv('brandy_materials.csv', index=False)


df_small = pd.read_csv("../../data/youtube_data/brandy_youtube_data.csv")

df_small["ScrapedData"] = df_small.apply(scrape_and_update, axis=1)



df_small.to_csv("brandy_small_materials.csv", index=False)
