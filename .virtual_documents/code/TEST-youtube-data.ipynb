from googleapiclient.discovery import build
import pandas as pd
from datetime import datetime
import re


# set up YouTube Data API 
api_key = "AIzaSyB4rEWrBMhi4lJEgfwsV386f44qwL3HxG4"
youtube = build('youtube', 'v3', developerKey=api_key)


brands = ["Shein", "Princess Polly", "Brandy Melville", "Nike",
          "Abercrombie", "Abercrombie and Fitch", "Abercrombie & Fitch", "Amazon"]
keywords = [ "fashion haul", "try-on haul", "thrift haul", "clothing haul"]

published_after = datetime(2023, 1, 1).isoformat() + 'Z'
published_before = datetime(2023, 12, 31).isoformat() + 'Z'


# search for videos
search_response = youtube.search().list(
    q=' '.join(brands), # combine keywords into single query string
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=30
).execute()


# TO DO:
# X - only output vids with links in bio (MONDAY)
# X - create separate datasets? with different brands/keyword search types (MONDAY)
# organize, further organize datasets in csv/excel (TUESDAY)
# help jasmine with regular expressions (TUESDAY)
# X - refine formula TODAY - talk to dr. mitra about this (MONDAY)
# formulate in QQQ for friday (WED OR THURS)

# process results
videos = []
for search_result in search_response.get('items', []):
    # gets and stores video id
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        # receive snippet part of data - title, description, tags, etc.
        part="snippet",
        id=video_id
    ).execute()

    # accesses description field of snipper
    description = video_response['items'][0]['snippet']['description']
    
    # extract links from description
    links = re.findall(r'(https?://\S+)', description)

    # print("Extracted links:", links)
    
    # add video title, description, and links (if there are links) to videos list
    videos.append({
        'title': search_result['snippet']['title'],
        # 'description': description,
        # 'publish_time': search_result['snippet']['publishedAt'],
        # 'video_id': video_id,
        'links': links
    })

filtered_videos = []

for video in videos:
    title = video['title'].lower()
    for brand in brands:
        if brand.lower() in title:
            filtered_videos.append(video)
            break  # Once we find a matching brand, we can move to the next video

print(filtered_videos)


# filter vids into separate lists based on BRANDS
filtered_vids_brands = {}

for brand in brands:
    print(brand)
    filtered_vids_brands[brand] = [
        video for video in videos
        if brand.lower() in video['title'].lower() and video['links']
    ]
    # print(filtered_vids_brands[brand])

for brand, vid_list in filtered_vids_brands.items():
    print(f"VIDEOS WITH '{brand}':")
    for video in vid_list:
        # print("Video Info:", video) 
        print("title:", video['title'])
        print("links:")
        for link in video['links']:
            print(link)
        print()


# export vids for each brand into separate csv files
for brand, vid_list in filtered_vids_brands.items():
    csv_filename = f"../data/{brand.replace(' ', '_')}_videos.csv"
    # df from list of videos
    df = pd.DataFrame(vid_list)
    # save df to csv
    df.to_csv(csv_filename, index=False)
    print(f"CSV file saved for '{brand}': {csv_filename}")


# filter vids into separate lists based on KEYWORDS
filtered_vids_keywords = {}

for keyword in keywords:
    filtered_vids_keywords[keyword] = [
        video for video in videos 
        if keyword.lower() in video['title'].lower() and video['links']
    ]
for keyword, vid_list in filtered_vids_keywords.items():
    print(f"VIDEOS WITH '{keyword}':")
    for video in vid_list:
        print("title:", video['title'])
        print("links:")
        for link in video['links']:
            print(link)
        print()


# only output videos with links in bios we can scrape
vids_with_links = []

for video in videos:
    if video['links']:
        vids_with_links.append(video)
    
for video in vids_with_links:
    print("Title:", video['title'])
    print("Links:")
    for link in video['links']:
        print(link)
    print()
