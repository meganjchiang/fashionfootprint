


from googleapiclient.discovery import build
import pandas as pd
from datetime import datetime
import re


# set up YouTube Data API 
api_key = "AIzaSyCTXXIHS8qogOyiQgnxjVNqf34IGPVDnDE"
youtube = build('youtube', 'v3', developerKey=api_key)





published_after = datetime(2023, 1, 1).isoformat() + 'Z'
published_before = datetime(2023, 12, 31).isoformat() + 'Z'








keywords = ['haul', 'clothing', 'clothes', 'shop', 'shopping', 'try on', 'try-on']
social_media_links = ['pinterest', 'youtube', 'twitter', 'instagram', 'tiktok', 'reddit', 'twitch', 'facebook', 'thmatc']





uniqlo_search_results = youtube.search().list(
    q='Uniqlo',
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=50
).execute()


uniqlo_videos = []
for search_result in uniqlo_search_results.get('items', []):
    # gets and stores video id
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        # receive snippet part of data - title, description, tags, etc.
        part="snippet",
        id=video_id
    ).execute()

    # access description field of snipper
    description = video_response['items'][0]['snippet']['description']
    
    # extract links from description
    links = re.findall(r'(https?://\S+)', description)

    # makes all titles lowercase so code can match on any version of title:
    # (e.g., UNIQLO, uniqlo, Uniqlo)
    title = search_result['snippet']['title'].lower()
    
    if 'uniqlo' in title:
        # filters out social media links
        filtered_links = [link for link in links if not any(keyword in link for keyword in social_media_links)]

        uniqlo_videos.append({
            'title': search_result['snippet']['title'],
            'links': filtered_links
        })


# only output videos with links in bios we can scrape
uniqlo_youtube_data = []

for video in uniqlo_videos:
    # check if vid has links
    if video['links']:
        # append the video to the filtered list
        uniqlo_youtube_data.append({
            'Title': video['title'],
            'Links': '\n'.join(video['links'])
        }) 





# search for videos
shein_search_results = youtube.search().list(
    q='Shein',
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=50
).execute()


shein_videos = []
for search_result in shein_search_results.get('items', []):
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        part="snippet",
        id=video_id
    ).execute()

    description = video_response['items'][0]['snippet']['description']
    
    links = re.findall(r'(https?://\S+)', description)
    
    title = search_result['snippet']['title'].lower()
    
    if 'shein' in title and any(keyword in title for keyword in keywords):
        filtered_links = [link for link in links if not any(keyword in link for keyword in social_media_links)]
        
        shein_videos.append({
            'title': search_result['snippet']['title'],
            'links': filtered_links
        })


shein_youtube_data = []

for video in shein_videos:
    if video['links']:
        shein_youtube_data.append({
            'Title': video['title'],
            'Links': '\n'.join(video['links'])
        })





# search for videos
prin_polly_search_results = youtube.search().list(
    q='Princess Polly',
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=50
).execute()


prin_polly_videos = []
for search_result in prin_polly_search_results.get('items', []):
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        part="snippet",
        id=video_id
    ).execute()

    description = video_response['items'][0]['snippet']['description']
    
    links = re.findall(r'(https?://\S+)', description)
    
    title = search_result['snippet']['title'].lower()
    
    if 'princess polly' in title:
        filtered_links = [link for link in links if not any(keyword in link for keyword in social_media_links)]
        
        prin_polly_videos.append({
            'title': search_result['snippet']['title'],
            'links': filtered_links
        })


prin_polly_youtube_data = []

for video in prin_polly_videos:
    if video['links']:
        prin_polly_youtube_data.append({
            'Title': video['title'],
            'Links': '\n'.join(video['links'])
        })





# search for videos
brandy_search_results = youtube.search().list(
    q=['Brandy Melville', 'Brandy'],
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=50
).execute()


brandy_videos = []
for search_result in brandy_search_results.get('items', []):
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        part="snippet",
        id=video_id
    ).execute()

    description = video_response['items'][0]['snippet']['description']
    
    links = re.findall(r'(https?://\S+)', description)
    
    title = search_result['snippet']['title'].lower()
    
    if 'brandy melville' in title or 'brandy' in title:
        filtered_links = [link for link in links if not any(keyword in link for keyword in social_media_links)]
        
        brandy_videos.append({
            'title': search_result['snippet']['title'],
            'links': filtered_links
        })


brandy_youtube_data = []

for video in brandy_videos:
    if video['links']:
        brandy_youtube_data.append({
            'Title': video['title'],
            'Links': '\n'.join(video['links'])
        })





# search for videos
nike_search_results = youtube.search().list(
    q='Nike',
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=50
).execute()


nike_videos = []
for search_result in nike_search_results.get('items', []):
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        part="snippet",
        id=video_id
    ).execute()

    description = video_response['items'][0]['snippet']['description']
    
    links = re.findall(r'(https?://\S+)', description)
    
    title = search_result['snippet']['title'].lower()
    
    if 'nike' in title:
        filtered_links = [link for link in links if not any(keyword in link for keyword in social_media_links)]

        nike_videos.append({
            'title': search_result['snippet']['title'],
            'links': filtered_links
        })


nike_youtube_data = []

for video in nike_videos:
    if video['links']:
        nike_youtube_data.append({
            'Title': video['title'],
            'Links': '\n'.join(video['links'])
        })





# search for videos
abercrombie_search_results = youtube.search().list(
    q='Abercrombie',
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=50
).execute()


abercrombie_videos = []
for search_result in abercrombie_search_results.get('items', []):
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        part="snippet",
        id=video_id
    ).execute()

    description = video_response['items'][0]['snippet']['description']
    
    links = re.findall(r'(https?://\S+)', description)
    
    title = search_result['snippet']['title'].lower()
    
    if 'abercrombie' in title:
        filtered_links = [link for link in links if not any(keyword in link for keyword in social_media_links)]

        abercrombie_videos.append({
            'title': search_result['snippet']['title'],
            'links': filtered_links
        })


abercrombie_youtube_data = []

for video in abercrombie_videos:
    if video['links']:
        abercrombie_youtube_data.append({
            'Title': video['title'],
            'Links': '\n'.join(video['links'])
        })





# search for videos
amazon_search_results = youtube.search().list(
    q='Amazon',
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=50
).execute()


amazon_videos = []
for search_result in amazon_search_results.get('items', []):
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        part="snippet",
        id=video_id
    ).execute()

    description = video_response['items'][0]['snippet']['description']
    
    links = re.findall(r'(https?://\S+)', description)
    
    title = search_result['snippet']['title'].lower()
    
    if 'amazon' in title:
        filtered_links = [link for link in links if not any(keyword in link for keyword in social_media_links)]

        amazon_videos.append({
            'title': search_result['snippet']['title'],
            'links': filtered_links
        })


amazon_youtube_data = []

for video in amazon_videos:
    if video['links']:
        amazon_youtube_data.append({
            'Title': video['title'],
            'Links': '\n'.join(video['links'])
        })
# the amazon data is a little weird since a lot of
# amazon related vids aren't hauls and also like
# amazon rainforest vids pop up LOL





# search for videos
alo_search_results = youtube.search().list(
    q=['Alo', 'Alo Yoga'],
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=50
).execute()


alo_videos = []
for search_result in alo_search_results.get('items', []):
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        part="snippet",
        id=video_id
    ).execute()

    description = video_response['items'][0]['snippet']['description']
    
    links = re.findall(r'(https?://\S+)', description)
    
    title = search_result['snippet']['title'].lower()
    
    if 'alo' in title or 'alo yoga' in title:
        filtered_links = [link for link in links if not any(keyword in link for keyword in social_media_links)]

        alo_videos.append({
            'title': search_result['snippet']['title'],
            'links': filtered_links
        })


alo_youtube_data = []

for video in alo_videos:
    if video['links']:
        alo_youtube_data.append({
            'Title': video['title'],
            'Links': '\n'.join(video['links'])
        })





# search for videos
reformation_search_results = youtube.search().list(
    q='Reformation',
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=50
).execute()


reformation_videos = []
for search_result in reformation_search_results.get('items', []):
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        part="snippet",
        id=video_id
    ).execute()

    description = video_response['items'][0]['snippet']['description']
    
    links = re.findall(r'(https?://\S+)', description)
    
    title = search_result['snippet']['title'].lower()
    
    if 'reformation' in title:
        filtered_links = [link for link in links if not any(keyword in link for keyword in social_media_links)]

        reformation_videos.append({
            'title': search_result['snippet']['title'],
            'links': filtered_links
        })


reformation_youtube_data = []

for video in reformation_videos:
    if video['links']:
        reformation_youtube_data.append({
            'Title': video['title'],
            'Links': '\n'.join(video['links'])
        })





# search for videos
asos_search_results = youtube.search().list(
    q='ASOS',
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=50
).execute()


asos_videos = []
for search_result in asos_search_results.get('items', []):
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        part="snippet",
        id=video_id
    ).execute()

    description = video_response['items'][0]['snippet']['description']
    
    links = re.findall(r'(https?://\S+)', description)
    
    title = search_result['snippet']['title'].lower()
    
    if 'asos' in title:
        filtered_links = [link for link in links if not any(keyword in link for keyword in social_media_links)]

        asos_videos.append({
            'title': search_result['snippet']['title'],
            'links': filtered_links
        })


asos_youtube_data = []

for video in asos_videos:
    if video['links']:
        asos_youtube_data.append({
            'Title': video['title'],
            'Links': '\n'.join(video['links'])
        })





# search for videos
forever21_search_results = youtube.search().list(
    q='Forever 21',
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=50
).execute()


forever21_videos = []
for search_result in forever21_search_results.get('items', []):
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        part="snippet",
        id=video_id
    ).execute()

    description = video_response['items'][0]['snippet']['description']
    
    links = re.findall(r'(https?://\S+)', description)
    
    title = search_result['snippet']['title'].lower()
    
    if 'forever 21' in title:
        filtered_links = [link for link in links if not any(keyword in link for keyword in social_media_links)]

        forever21_videos.append({
            'title': search_result['snippet']['title'],
            'links': filtered_links
        })


forever21_youtube_data = []

for video in forever21_videos:
    if video['links']:
        forever21_youtube_data.append({
            'Title': video['title'],
            'Links': '\n'.join(video['links'])
        })





# search for videos
am_eagle_search_results = youtube.search().list(
    q='American Eagle',
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=50
).execute()


am_eagle_videos = []
for search_result in am_eagle_search_results.get('items', []):
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        part="snippet",
        id=video_id
    ).execute()

    description = video_response['items'][0]['snippet']['description']
    
    links = re.findall(r'(https?://\S+)', description)
    
    title = search_result['snippet']['title'].lower()
    
    if 'american eagle' in title and any(keyword in title for keyword in keywords):
        filtered_links = [link for link in links if not any(keyword in link for keyword in social_media_links)]

        am_eagle_videos.append({
            'title': search_result['snippet']['title'],
            'links': filtered_links
        })


am_eagle_youtube_data = []

for video in am_eagle_videos:
    if video['links']:
        am_eagle_youtube_data.append({
            'Title': video['title'],
            'Links': '\n'.join(video['links'])
        })





# search for videos
adidas_search_results = youtube.search().list(
    q='Adidas',
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=50
).execute()


adidas_videos = []
for search_result in adidas_search_results.get('items', []):
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        part="snippet",
        id=video_id
    ).execute()

    description = video_response['items'][0]['snippet']['description']
    
    links = re.findall(r'(https?://\S+)', description)
    
    title = search_result['snippet']['title'].lower()
    
    if 'adidas' in title:
        filtered_links = [link for link in links if not any(keyword in link for keyword in social_media_links)]

        adidas_videos.append({
            'title': search_result['snippet']['title'],
            'links': filtered_links
        })


adidas_youtube_data = []

for video in adidas_videos:
    if video['links']:
        adidas_youtube_data.append({
            'Title': video['title'],
            'Links': '\n'.join(video['links'])
        })





# search for videos
aritzia_search_results = youtube.search().list(
    q='Aritzia',
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=50
).execute()


aritzia_videos = []
for search_result in aritzia_search_results.get('items', []):
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        part="snippet",
        id=video_id
    ).execute()

    description = video_response['items'][0]['snippet']['description']
    
    links = re.findall(r'(https?://\S+)', description)
    
    title = search_result['snippet']['title'].lower()
    
    if 'aritzia' in title:
        filtered_links = [link for link in links if not any(keyword in link for keyword in social_media_links)]

        aritzia_videos.append({
            'title': search_result['snippet']['title'],
            'links': filtered_links
        })


aritzia_youtube_data = []

for video in aritzia_videos:
    if video['links']:
        aritzia_youtube_data.append({
            'Title': video['title'],
            'Links': '\n'.join(video['links'])
        })





all_youtube_data = {
    'uniqlo_youtube_data': uniqlo_youtube_data,
    'shein_youtube_data': shein_youtube_data,
    'prin_polly_youtube_data': prin_polly_youtube_data,
    'brandy_youtube_data': brandy_youtube_data,
    'nike_youtube_data': nike_youtube_data,
    'abercombie_youtube_data': abercrombie_youtube_data,
    'amazon_youtube_data': amazon_youtube_data,
    'alo_youtube_data': alo_youtube_data,
    'reformation_youtube_data': reformation_youtube_data,
    'asos_youtube_data': asos_youtube_data,
    'forever21_youtube_data': forever21_youtube_data,
    'am_eagle_youtube_data': am_eagle_youtube_data,
    'adidas_youtube_data': adidas_youtube_data,
    'aritzia_youtube_data': aritzia_youtube_data
}

# iterate over each youtube_data and save it to a csv in the youtube_data folder
for name, data in all_youtube_data.items():
    filename = f"../data/youtube_data/{name}.csv"
    pd.DataFrame(data).to_csv(filename, index=False)
    print(f"CSV file saved: {filename}")








    # q=' '.join(brands),  # combine keywords into single query string


# filter vids into separate lists based on BRANDS
# filtered_vids_brands = {}

# for brand in brands:
#     filtered_vids_brands[brand] = [
#         video for video in videos 
#         if brand.lower() in video['title'].lower() and video['links']
#     ]
# for brand, vid_list in filtered_vids_brands.items():
#     print(f"VIDEOS WITH '{brand}':")
#     for video in vid_list:
#         print("title:", video['title'])
#         print("links:")
#         for link in video['links']:
#             print(link)
#         print()


# filter vids into separate lists based on BRANDS

# pagination - from in class
# filtered_vids_brands_2 = {}

# for brand in brands_2:
#     filtered_vids_brands_2[brand] = [
#         video for video in videos 
#         if brand.lower() in video['title'].lower() and video['links']
#     ]
# for brand, vid_list in filtered_vids_brands_2.items():
#     print(f"VIDEOS WITH '{brand}':")
#     for video in vid_list:
#         print("title:", video['title'])
#         print("links:")
#         for link in video['links']:
#             print(link)
#         print()


# youtube_data = []

# # iterate over filtered videos and construct data for csv
# for brand, vid_list in filtered_vids_brands.items():
#     for video in vid_list:
#         title = video['title']
#         links = '\n'.join(video['links'])  
#         youtube_data.append({'Brand': brand, 'Title': title, 'Links': links})

# for brand, vid_list in filtered_vids_brands_2.items():
#     for video in vid_list:
#         title = video['title']
#         links = '\n'.join(video['links'])  
#         youtube_data.append({'Brand': brand, 'Title': title, 'Links': links})

# # create df
# youtube_df = pd.DataFrame(youtube_data)

# # export df to csv
# youtube_df.to_csv('../data/filtered_videos.csv', index=False)


    # add video title, description, and links (if there are links) to videos list
    # uniqlo_videos.append({
    #     'title': search_result['snippet']['title'],
    #     # 'description': description,
    #     # 'publish_time': search_result['snippet']['publishedAt'],
    #     # 'video_id': video_id,
    #     'links': links
    # })


# for video in uniqlo_youtube_data:
#     print("Title:", video['title'])
#     print("Links:")
#     for link in video['links']:
#         print(link)
#     print()
