from googleapiclient.discovery import build
import pandas as pd
from datetime import datetime
import re


# set up YouTube Data API 
api_key = "AIzaSyB4rEWrBMhi4lJEgfwsV386f44qwL3HxG4"
youtube = build('youtube', 'v3', developerKey=api_key)


brands = ["Shein", "Princess Polly", "Brandy Melville", "Nike", "Brandy"]
brands_2 = ["Uniqlo", "Aritzia", "Abercrombie & Fitch", "Abercrombie", "American Eagle",
            "ASOS", "Forever 21", "Adidas", "Amazon"]
published_after = datetime(2023, 1, 1).isoformat() + 'Z'
published_before = datetime(2023, 12, 31).isoformat() + 'Z'


# search for videos
search_response = youtube.search().list(
    q=' '.join(brands),  # combine keywords into single query string
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=100
).execute()


videos = []
for search_result in search_response.get('items', []):
    # gets and stores video id
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        # receive snippet part of data - title, description, tags, etc.
        part="snippet",
        id=video_id
    ).execute()

    # accesses description field of snipper
    description = video_response['items'][0]['snippet']['description']
    
    # extract links from description
    links = re.findall(r'(https?://\S+)', description)
    
    # add video title, description, and links (if there are links) to videos list
    videos.append({
        'title': search_result['snippet']['title'],
        # 'description': description,
        # 'publish_time': search_result['snippet']['publishedAt'],
        # 'video_id': video_id,
        'links': links
    })


# filter vids into separate lists based on BRANDS
filtered_vids_brands = {}

for brand in brands:
    filtered_vids_brands[brand] = [
        video for video in videos 
        if brand.lower() in video['title'].lower() and video['links']
    ]
for brand, vid_list in filtered_vids_brands.items():
    print(f"VIDEOS WITH '{brand}':")
    for video in vid_list:
        print("title:", video['title'])
        print("links:")
        for link in video['links']:
            print(link)
        print()


# filter vids into separate lists based on BRANDS
filtered_vids_brands_2 = {}

for brand in brands_2:
    filtered_vids_brands_2[brand] = [
        video for video in videos 
        if brand.lower() in video['title'].lower() and video['links']
    ]
for brand, vid_list in filtered_vids_brands_2.items():
    print(f"VIDEOS WITH '{brand}':")
    for video in vid_list:
        print("title:", video['title'])
        print("links:")
        for link in video['links']:
            print(link)
        print()


youtube_data = []

# iterate over filtered videos and construct data for csv
for brand, vid_list in filtered_vids_brands.items():
    for video in vid_list:
        title = video['title']
        links = '\n'.join(video['links'])  
        youtube_data.append({'Brand': brand, 'Title': title, 'Links': links})

for brand, vid_list in filtered_vids_brands_2.items():
    for video in vid_list:
        title = video['title']
        links = '\n'.join(video['links'])  
        youtube_data.append({'Brand': brand, 'Title': title, 'Links': links})

# create df
youtube_df = pd.DataFrame(youtube_data)

# export df to csv
youtube_df.to_csv('../data/filtered_videos.csv', index=False)



