








from googleapiclient.discovery import build
import pandas as pd
from datetime import datetime
import re

# set up YouTube Data API 
api_key = "AIzaSyB4rEWrBMhi4lJEgfwsV386f44qwL3HxG4"
youtube = build('youtube', 'v3', developerKey=api_key)


# search by keywords
keywords = ['haul', 'clothing', 'clothes', 'shop', 'shopping', 'try on', 'try-on']

# set time period to be in 2023
published_after = datetime(2023, 1, 1).isoformat() + 'Z'
published_before = datetime(2023, 12, 31).isoformat() + 'Z'


# search for videos
search_response = youtube.search().list(
    q=keywords, 
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=1 # returns 1 result(video) that match w/criteria
).execute()


# process results
videos = []
for search_result in search_response.get('items', []):
    # get and store video id
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        # receive snippet part of data - title, description, tags, etc.
        part="snippet",
        id=video_id
    ).execute()

    # accesses description field of snipper
    description = video_response['items'][0]['snippet']['description']
    
    # extract links from description
    links = re.findall(r'(https?://\S+)', description)
    
    # add video title, description, and links (if there are links) to videos list
    videos.append({
        'title': search_result['snippet']['title'],
        'links': links
    })


# filter vids into separate lists based on keywords
filtered_vids_keywords = {}

for keyword in keywords:
    filtered_vids_keywords[keyword] = [
        video for video in videos 
        if keyword.lower() in video['title'].lower() and video['links']
    ]
for keyword, vid_list in filtered_vids_keywords.items():
    print(f"VIDEOS WITH '{keyword}':")
    for video in vid_list:
        print("title:", video['title'])
        print("links:")
        for link in video['links']:
            print(link)
        print()











social_media_links = ['pinterest', 'youtube', 'twitter', 'instagram', 'tiktok', 'reddit', 'twitch', 'facebook', 'thmatc']


# search for videos
am_eagle_search_results = youtube.search().list(
    q='American Eagle', # search by a specific brand rather than set of fashion-related keywords
    part='snippet',
    type='video',
    publishedAfter=published_after,
    publishedBefore=published_before,
    maxResults=50
).execute()


am_eagle_videos = []
for search_result in am_eagle_search_results.get('items', []):
    video_id = search_result['id']['videoId']
    video_response = youtube.videos().list(
        part="snippet",
        id=video_id
    ).execute()

    description = video_response['items'][0]['snippet']['description']
    
    links = re.findall(r'(https?://\S+)', description)

    # makes all titles lowercase so code can match on any version of title:
    # (e.g., American Eagle, american eagle, AMERICAN EAGLE)
    title = search_result['snippet']['title'].lower()

    # filters based on 'american eagle' in title and fashion-related keywords
    if 'american eagle' in title and any(keyword in title for keyword in keywords):
        # filters out social media links
        filtered_links = [link for link in links if not any(keyword in link for keyword in social_media_links)]

        am_eagle_videos.append({
            'title': search_result['snippet']['title'],
            'links': filtered_links
        })


# only output videos with links in bios we can scrape
am_eagle_youtube_data = []

for video in am_eagle_videos:
    # check if vid has links
    if video['links']:
        # append the video to the filtered list
        am_eagle_youtube_data.append({
            'Title': video['title'],
            'Links': '\n'.join(video['links'])
        })

# formatted this way so it can be easily converted to csv using to_csv function from pandas
print(am_eagle_youtube_data)






