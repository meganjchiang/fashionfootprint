








from googleapiclient.discovery import build
import pandas as pd
from datetime import datetime
import re
import os
import config

# set up YouTube Data API 
api_key = config.API_KEY
youtube = build('youtube', 'v3', developerKey=api_key)


def get_youtube_data(brand_name):
    published_after = datetime(2023, 9, 1).isoformat() + 'Z'
    published_before = datetime(2024, 4, 24).isoformat() + 'Z'
    keywords = ['haul', 'clothing', 'clothes', 'shop', 'shopping', 'try on', 'try-on', 'review', 'styling']
    social_media_links = ['pinterest', 'youtube', 'twitter', 'instagram', 'tiktok',
                          'reddit', 'twitch', 'facebook', 'thmatc', 'spotify']

    # fetch initial search results
    search_results = []
    request = youtube.search().list(
        q=brand_name,
        part='snippet',
        type='video',
        publishedAfter=published_after,
        publishedBefore=published_before,
        maxResults=10
    )
    response = request.execute()
    next_page_token = response.get('nextPageToken')
    
    while next_page_token is not None:
        # send request to YouTube API
        request = youtube.search().list(
            q=brand_name,
            part='snippet',
            type='video',
            publishedAfter=published_after,
            publishedBefore=published_before,
            maxResults=5,
            pageToken=next_page_token
        )
        response = request.execute()
        # add items from response 
        search_results.extend(response.get('items',[]))
        # get next page token for pagination
        next_page_token = response.get('nextPageToken')

    # process search results to extract relevant vid data
    brand_videos = []
    for search_result in search_results:
        # gets and stores video id
        video_id = search_result['id']['videoId']
        video_response = youtube.videos().list(
            # receive snippet part of data - title, description, tags, etc.
            part="snippet",
            id=video_id
        ).execute()

        # access description field of snipper
        description = video_response['items'][0]['snippet']['description']
        # extract links from description
        links = re.findall(r'(https?://\S+)', description)
        # makes all titles lowercase so code can match on any version of title:
        title = search_result['snippet']['title'].lower()

        # filters based on brand name and fashion related keywords
        if brand_name.lower() in title and any(keyword in title for keyword in keywords):
            # filters out social media links
            filtered_links = [link for link in links if not any(keyword in link for keyword in social_media_links)]
            # get link to video
            video_link = f"https://www.youtube.com/watch?v={video_id}"
            brand_videos.append({
                'title': search_result['snippet']['title'],
                'links': filtered_links,
                'videoLink': video_link
            })

    # process data and format for csv
    brand_youtube_data = []
    for video in brand_videos:
        if video['links']:
            brand_youtube_data.append({
                'Title': video['title'],
                'Links': '\n'.join(video['links']),
                'VideoLink': video['videoLink']
            })

    return brand_youtube_data


youtube_data = get_youtube_data('Uniqlo')

for video in youtube_data:
    print(f"Title: {video['Title']}")
    print(f"Links: {video['Links']}")
    print(f"Video Link: {video['VideoLink']}")
    print()
print()


# reads uniqlo CSV into a pandas df
uniqlo_df = pd.read_csv("../data/youtube_data/uniqlo_youtube_data.csv")

# display the first 5 rows
print("First 5 rows of Uniqlo YouTube data:")
print(uniqlo_df.head())






























