{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9de8cf0f-fddc-4271-8e39-f00f17364bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5b5ffd0-1cfb-44d8-9c1c-1f0233832a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up YouTube Data API \n",
    "api_key = \"AIzaSyB4rEWrBMhi4lJEgfwsV386f44qwL3HxG4\"\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98cdb606-c895-4ec1-abb7-32917f973f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = [\"Shein\", \"Princess Polly\", \"Brandy Melville\", \"Nike\",\n",
    "          \"Abercrombie\", \"Abercrombie and Fitch\", \"Abercrombie & Fitch\", \"Amazon\"]\n",
    "keywords = [ \"fashion haul\", \"try-on haul\", \"thrift haul\", \"clothing haul\"]\n",
    "\n",
    "published_after = datetime(2023, 1, 1).isoformat() + 'Z'\n",
    "published_before = datetime(2023, 12, 31).isoformat() + 'Z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f9ae4c7-a927-45c7-9b9c-239ae0f8fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for videos\n",
    "search_response = youtube.search().list(\n",
    "    q=' '.join(brands), # combine keywords into single query string\n",
    "    part='snippet',\n",
    "    type='video',\n",
    "    publishedAfter=published_after,\n",
    "    publishedBefore=published_before,\n",
    "    maxResults=30\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c96dc8bf-ce92-445f-b145-081819d8a4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'HUGE Vacation Try On Haul | Revolve Abercrombie &amp; Princess Polly', 'links': []}]\n"
     ]
    }
   ],
   "source": [
    "# TO DO:\n",
    "# X - only output vids with links in bio (MONDAY)\n",
    "# X - create separate datasets? with different brands/keyword search types (MONDAY)\n",
    "# organize, further organize datasets in csv/excel (TUESDAY)\n",
    "# help jasmine with regular expressions (TUESDAY)\n",
    "# X - refine formula TODAY - talk to dr. mitra about this (MONDAY)\n",
    "# formulate in QQQ for friday (WED OR THURS)\n",
    "\n",
    "# process results\n",
    "videos = []\n",
    "for search_result in search_response.get('items', []):\n",
    "    # gets and stores video id\n",
    "    video_id = search_result['id']['videoId']\n",
    "    video_response = youtube.videos().list(\n",
    "        # receive snippet part of data - title, description, tags, etc.\n",
    "        part=\"snippet\",\n",
    "        id=video_id\n",
    "    ).execute()\n",
    "\n",
    "    # accesses description field of snipper\n",
    "    description = video_response['items'][0]['snippet']['description']\n",
    "    \n",
    "    # extract links from description\n",
    "    links = re.findall(r'(https?://\\S+)', description)\n",
    "\n",
    "    # print(\"Extracted links:\", links)\n",
    "    \n",
    "    # add video title, description, and links (if there are links) to videos list\n",
    "    videos.append({\n",
    "        'title': search_result['snippet']['title'],\n",
    "        # 'description': description,\n",
    "        # 'publish_time': search_result['snippet']['publishedAt'],\n",
    "        # 'video_id': video_id,\n",
    "        'links': links\n",
    "    })\n",
    "\n",
    "filtered_videos = []\n",
    "\n",
    "for video in videos:\n",
    "    title = video['title'].lower()\n",
    "    for brand in brands:\n",
    "        if brand.lower() in title:\n",
    "            filtered_videos.append(video)\n",
    "            break  # Once we find a matching brand, we can move to the next video\n",
    "\n",
    "print(filtered_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b605e3df-14d4-48d9-af0b-aedf6dcaa23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter vids into separate lists based on BRANDS\n",
    "filtered_vids_brands = {}\n",
    "\n",
    "for brand in brands:\n",
    "    print(brand)\n",
    "    filtered_vids_brands[brand] = [\n",
    "        video for video in videos\n",
    "        if brand.lower() in video['title'].lower() and video['links']\n",
    "    ]\n",
    "    # print(filtered_vids_brands[brand])\n",
    "\n",
    "for brand, vid_list in filtered_vids_brands.items():\n",
    "    print(f\"VIDEOS WITH '{brand}':\")\n",
    "    for video in vid_list:\n",
    "        # print(\"Video Info:\", video) \n",
    "        print(\"title:\", video['title'])\n",
    "        print(\"links:\")\n",
    "        for link in video['links']:\n",
    "            print(link)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06172a6a-194a-4f20-98a3-a74937e49645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export vids for each brand into separate csv files\n",
    "for brand, vid_list in filtered_vids_brands.items():\n",
    "    csv_filename = f\"../data/{brand.replace(' ', '_')}_videos.csv\"\n",
    "    # df from list of videos\n",
    "    df = pd.DataFrame(vid_list)\n",
    "    # save df to csv\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"CSV file saved for '{brand}': {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b8950c-6c96-4e59-91e2-23b8a2652b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter vids into separate lists based on KEYWORDS\n",
    "filtered_vids_keywords = {}\n",
    "\n",
    "for keyword in keywords:\n",
    "    filtered_vids_keywords[keyword] = [\n",
    "        video for video in videos \n",
    "        if keyword.lower() in video['title'].lower() and video['links']\n",
    "    ]\n",
    "for keyword, vid_list in filtered_vids_keywords.items():\n",
    "    print(f\"VIDEOS WITH '{keyword}':\")\n",
    "    for video in vid_list:\n",
    "        print(\"title:\", video['title'])\n",
    "        print(\"links:\")\n",
    "        for link in video['links']:\n",
    "            print(link)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6f1a4f-7434-479a-adde-0539351deabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only output videos with links in bios we can scrape\n",
    "vids_with_links = []\n",
    "\n",
    "for video in videos:\n",
    "    if video['links']:\n",
    "        vids_with_links.append(video)\n",
    "    \n",
    "for video in vids_with_links:\n",
    "    print(\"Title:\", video['title'])\n",
    "    print(\"Links:\")\n",
    "    for link in video['links']:\n",
    "        print(link)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
