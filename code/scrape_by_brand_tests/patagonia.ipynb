{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Links</th>\n",
       "      <th>VideoLink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patagonia Guidewater Backpack Review</td>\n",
       "      <td>https://bit.ly/4aIg9mh\\nhttps://bit.ly/40RxmFb...</td>\n",
       "      <td>https://www.youtube.com/watch?v=1r-sdnACmsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[박영준TV] [Review] Patagonia Capilene Cool Daily...</td>\n",
       "      <td>https://cafe.naver.com/windstopper</td>\n",
       "      <td>https://www.youtube.com/watch?v=jNL9GO2yCI0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0               Patagonia Guidewater Backpack Review   \n",
       "1  [박영준TV] [Review] Patagonia Capilene Cool Daily...   \n",
       "\n",
       "                                               Links  \\\n",
       "0  https://bit.ly/4aIg9mh\\nhttps://bit.ly/40RxmFb...   \n",
       "1                 https://cafe.naver.com/windstopper   \n",
       "\n",
       "                                     VideoLink  \n",
       "0  https://www.youtube.com/watch?v=1r-sdnACmsA  \n",
       "1  https://www.youtube.com/watch?v=jNL9GO2yCI0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/youtube_data/patagonia_youtube_data.csv')\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_patagonia(url):\n",
    "    try:\n",
    "        # Set Chrome options for headless mode\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        \n",
    "        # Initialize the WebDriver\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        \n",
    "        # Open the webpage\n",
    "        driver.get(url)\n",
    "\n",
    "        if 'patagonia.com' not in driver.current_url:\n",
    "            return {'item': 'Unsupported URL', 'url': url}\n",
    "        \n",
    "        # Wait for the page to fully load\n",
    "        time.sleep(5)  # Adjust the wait time as needed\n",
    "        \n",
    "        # Get the page source after interactions\n",
    "        page_source = driver.page_source\n",
    "\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "        # get title\n",
    "        # title = (driver.find_element(By.CLASS_NAME, 'h5 pdp-intro__title')).text\n",
    "        title = ((soup.find('h1', class_='h5 pdp-intro__title')).text).strip()\n",
    "        \n",
    "        # Close the WebDriver once done to avoid multiple instances\n",
    "        driver.quit()\n",
    "        \n",
    "        materials_element = soup.find('div', id='collapsible-2')\n",
    "\n",
    "        # Extract all text from the div element\n",
    "        all_text = (materials_element.get_text(separator='\\n', strip=True)).split('\\n')\n",
    "\n",
    "        possible_materials = [material for material in all_text if '%' in material][0]\n",
    "\n",
    "        # list of materials to match\n",
    "        materials_list = ['cotton', 'recycled cotton', 'organic cotton', 'polyester', 'recycled polyester', 'nylon',\n",
    "            'recycled nylon', 'acrylic', 'spandex', 'flax', 'linen', 'hemp', 'cupro', 'lyocell', 'tencel',\n",
    "            'refibra', 'modal', 'tencel modal', 'viscose', 'bamboo', 'lenzing viscose', 'ecovero', 'silk',\n",
    "            'alpaca', 'wool', 'recycled wool', 'cashmere', 'recycled Cashmere']\n",
    "\n",
    "        # create a regex pattern to match any material from the list\n",
    "        material_pattern = '|'.join(materials_list)\n",
    "\n",
    "        # regex pattern to match the specific percentages and material\n",
    "        pattern = rf'(\\d+)% ({material_pattern})'\n",
    "\n",
    "        fabric_percentages = re.findall(pattern, possible_materials)\n",
    "    \n",
    "        percentages = [int(material[0]) for material in fabric_percentages]\n",
    "        # make sure percentages sum to 100\n",
    "        if sum(percentages) == 100:\n",
    "            materials = {}\n",
    "\n",
    "            for material_comp in fabric_percentages:\n",
    "                percent = material_comp[0]\n",
    "                fabric = (material_comp[1]).lower()\n",
    "                materials[fabric] = percent\n",
    "\n",
    "                final_data = {'item': title}\n",
    "                final_data.update(materials)\n",
    "\n",
    "        return final_data\n",
    "\n",
    "    except:\n",
    "        return {'item': 'No Data', 'url': url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': \"Men's Classic Retro-X® Fleece Jacket\", 'polyester': '100'}\n",
      "{'item': \"Women's Mainstay Top\", 'organic cotton': '60', 'recycled polyester': '40'}\n",
      "{'item': 'Guidewater Backpack 29L', 'recycled nylon': '100'}\n"
     ]
    }
   ],
   "source": [
    "# URL of the webpage you want to scrape\n",
    "urls = [\n",
    "    'https://www.patagonia.com/product/mens-classic-retro-x-fleece-jacket/195699845640.html?s_kwcid=17928&utm_source=google&utm_medium=cpc&utm_campaign=BB_Ecomm_Shopping_ALL_WBSP_SaleKWs&gad_source=1&gclid=CjwKCAjw5v2wBhBrEiwAXDDoJd8XQGUW_sof8fEfoDRQUdlBPIlrxyB6fyngvB0--73eUmTbzjhBZBoCa84QAvD_BwE',\n",
    "    'https://www.patagonia.com/product/womens-mainstay-lightweight-top/42315.html?dwvar_42315_color=LTPG&cgid=womens-tops-short-sleeve',\n",
    "    'https://www.patagonia.com/product/guidewater-submersible-waterproof-backpack-29-liters/49165.html?avad=286573_f3964eac5&netid=1&pubid=228673&utm_source=www.thewadinglist.com&utm_medium=affiliate&utm_campaign=Custom+Link&src=cl&src=avl'\n",
    "]\n",
    "\n",
    "for url in urls:\n",
    "    # Call the function to scrape the website\n",
    "    data = scrape_patagonia(url)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_and_update(row):\n",
    "    links_list = row[\"Links\"].split('\\n')\n",
    "    scraped_data_combined = \"\"\n",
    "\n",
    "    for link in links_list:\n",
    "        scraped_data = scrape_patagonia(link)\n",
    "        scraped_data_combined += str(scraped_data) + \"\\n\"\n",
    "\n",
    "    return scraped_data_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ScrapedData'] = df.apply(scrape_and_update, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('materials_data/patagonia_materials.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
