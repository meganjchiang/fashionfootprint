{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/youtube_data/uniqlo_youtube_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Links</th>\n",
       "      <th>VideoLink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I ordered EVERY JEANS From UNIQLO - WORTH IT? ...</td>\n",
       "      <td>https://www.uniqlo.com/in/en/special-feature/j...</td>\n",
       "      <td>https://www.youtube.com/watch?v=QKhGbM_GkYo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "4  I ordered EVERY JEANS From UNIQLO - WORTH IT? ...   \n",
       "\n",
       "                                               Links  \\\n",
       "4  https://www.uniqlo.com/in/en/special-feature/j...   \n",
       "\n",
       "                                     VideoLink  \n",
       "4  https://www.youtube.com/watch?v=QKhGbM_GkYo  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# works but a limitation is that it cannot pull out materials for different components\n",
    "def scrape_uniqlo(url, wait_time=2):\n",
    "    try:\n",
    "        user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\"\n",
    "        # Set Chrome options for headless mode\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(f\"user-agent={user_agent}\")\n",
    "        interactive_element_xpath = '//*[@id=\"productMaterialDescription\"]'\n",
    "        loaded_content_xpath = '//*[@id=\"productMaterialDescription-content\"]/dl/dd[1]/p'\n",
    "        title_xpath = '//*[@id=\"root\"]/div[4]/div/section/div[2]/div[2]/div[1]/div/ul/li[1]/h1'\n",
    "\n",
    "        # Initialize the WebDriver with headless mode\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        \n",
    "        # Open the webpage\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the specified time before clicking the interactive element\n",
    "        time.sleep(wait_time)  # Wait for the specified time in seconds\n",
    "\n",
    "        # Find the interactive element\n",
    "        interactive_element = driver.find_element(By.XPATH, interactive_element_xpath)\n",
    "        \n",
    "        # Click the interactive element\n",
    "        interactive_element.click()\n",
    "\n",
    "        # Wait for the loaded content to be visible\n",
    "        loaded_element = WebDriverWait(driver, wait_time).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, loaded_content_xpath))\n",
    "        )\n",
    "\n",
    "        # Once loaded, scrape the content\n",
    "        dynamic_content = loaded_element.text\n",
    "        \n",
    "        # Scrape the title\n",
    "        title_element = driver.find_element(By.XPATH, title_xpath)\n",
    "        title = title_element.text\n",
    "        \n",
    "        # Extract all material percentages from the dynamic content\n",
    "        material_pattern = r'(\\d+)%\\s*(\\w+)'\n",
    "        material_matches = re.findall(material_pattern, dynamic_content)\n",
    "        \n",
    "        # Create a dictionary to store the scraped data\n",
    "        scraped_data = {\"item\": title}\n",
    "        for percent, material in material_matches:\n",
    "            # Convert percentage to integer\n",
    "            percent = int(percent)\n",
    "            # Update the dictionary with the material percentage\n",
    "            scraped_data[material.lower()] = percent\n",
    "        \n",
    "        return scraped_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        # Close the WebDriver\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRAPING CODE\n",
    "def scrape_and_update(row):\n",
    "    links_list = row[\"Links\"].split('\\n')\n",
    "    scraped_data_combined = \"\"\n",
    "\n",
    "    for link in links_list:\n",
    "        print(f\"Scraping data from link: {link}\")\n",
    "        scraped_data = scrape_uniqlo(link)\n",
    "        if scraped_data:\n",
    "            scraped_data_combined += str(scraped_data) + \"\\n\"\n",
    "        time.sleep(3)\n",
    "\n",
    "    return scraped_data_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_2024_small = pd.read_csv(\"../../data/youtube_data/SMALL-uniqlo-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_2024_small[\"ScrapedData\"] = df_test_2024_small.apply(scrape_and_update, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_2024_small.to_csv('SMALL_uniqlo_materials.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"ScrapedData\"] = df.apply(scrape_and_update, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('uniqlo_videos_materials.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code!! It works!!\n",
    "# Scraping stuff\n",
    "top_row = df.iloc[0]\n",
    "links_list = top_row[\"Links\"].split('\\n')\n",
    "\n",
    "for link in links_list:\n",
    "    print(f\"Scraping data from Uniqlo link: {link}\")\n",
    "    scraped_data = scrape_uniqlo(link)\n",
    "    if scraped_data:\n",
    "        print(scraped_data)\n",
    "        print()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': 'Linen Blend Printed Open Collar Short-Sleeve Shirt', 'rayon': 47, 'linen': 35, 'cotton': 18}\n"
     ]
    }
   ],
   "source": [
    "def scrape_uniqlo(url, wait_time=2):\n",
    "    try:\n",
    "        user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36\"\n",
    "        # Set Chrome options for headless mode\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(f\"user-agent={user_agent}\")\n",
    "        interactive_element_xpath = '//*[@id=\"productMaterialDescription\"]'\n",
    "        loaded_content_xpath = '//*[@id=\"productMaterialDescription-content\"]/dl/dd[1]/p'\n",
    "        title_xpath = '//*[@id=\"root\"]/div[4]/div/section/div[2]/div[2]/div[1]/div/ul/li[1]/h1'\n",
    "\n",
    "        # Initialize the WebDriver with headless mode\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        \n",
    "        # Open the webpage\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the specified time before clicking the interactive element\n",
    "        time.sleep(wait_time)  # Wait for the specified time in seconds\n",
    "\n",
    "        # Find the interactive element\n",
    "        interactive_element = driver.find_element(By.XPATH, interactive_element_xpath)\n",
    "        \n",
    "        # Click the interactive element\n",
    "        interactive_element.click()\n",
    "\n",
    "        # Wait for the loaded content to be visible\n",
    "        loaded_element = WebDriverWait(driver, wait_time).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, loaded_content_xpath))\n",
    "        )\n",
    "\n",
    "        # Once loaded, scrape the content\n",
    "        dynamic_content = loaded_element.text\n",
    "        \n",
    "        # Scrape the title\n",
    "        title_element = driver.find_element(By.XPATH, title_xpath)\n",
    "        title = title_element.text\n",
    "        \n",
    "        # Extract all material percentages from the dynamic content\n",
    "        material_pattern = r'(\\d+)%\\s*(\\w+)'\n",
    "        material_matches = re.findall(material_pattern, dynamic_content)\n",
    "        \n",
    "        # Create a dictionary to store the scraped data\n",
    "        scraped_data = {\"item\": title}\n",
    "        for percent, material in material_matches:\n",
    "            # Convert percentage to integer\n",
    "            percent = int(percent)\n",
    "            # Update the dictionary with the material percentage\n",
    "            scraped_data[material.lower()] = percent\n",
    "        \n",
    "        return scraped_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        # Close the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "url = \"https://www.uniqlo.com/us/en/products/E467247-000/00?colorDisplayCode=41&sizeDisplayCode=003\"\n",
    "dynamic_content = scrape_uniqlo(url)\n",
    "if dynamic_content:\n",
    "    print(dynamic_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
